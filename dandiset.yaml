# DO NOT EDIT THIS FILE LOCALLY. ALL LOCAL UPDATES WILL BE LOST.
# It can be edited online at https://dandiarchive.org/dandiset/001253
# and obtained from the dandiarchive.
'@context': https://raw.githubusercontent.com/dandi/schema/master/releases/0.6.8/context.json
access:
- schemaKey: AccessRequirements
  status: dandi:OpenAccess
assetsSummary:
  numberOfBytes: 0
  numberOfFiles: 0
  schemaKey: AssetsSummary
citation: Uchida, Naoshige (2024) An opponent striatal circuit for distributional
  reinforcement learning (Version draft) [Data set]. DANDI archive. https://dandiarchive.org/dandiset/001253/draft
contributor:
- affiliation: []
  email: uchida@mcb.harvard.edu
  includeInCitation: true
  name: Uchida, Naoshige
  roleName:
  - dcite:ContactPerson
  schemaKey: Person
dateCreated: '2024-11-10T15:51:35.745964+00:00'
description: 'Machine learning research has achieved large performance gains on a
  wide range of tasks by expanding the learning target from mean rewards to entire
  probability distributions of rewards — an approach known as distributional reinforcement
  learning (RL). The mesolimbic dopamine system is thought to underlie RL in the mammalian
  brain by updating a representation of mean value in the striatum, but little is
  known about whether, where, and how neurons in this circuit encode information about
  higher-order moments of reward distributions. To fill this gap, we used high-density
  probes (Neuropixels) to record striatal activity from mice performing a classical
  conditioning task in which reward mean, reward variance, and stimulus identity were
  independently manipulated. In contrast to traditional RL accounts, we found robust
  evidence for abstract encoding of variance in the striatum. Remarkably, chronic
  ablation of dopamine inputs disorganized these distributional representations in
  the striatum without interfering with mean value coding. Two-photon calcium imaging
  and optogenetics revealed that the two major classes of striatal medium spiny neurons
  — D1 and D2 MSNs — contributed to this code by preferentially encoding the right
  and left tails of the reward distribution, respectively. We synthesize these findings
  into a new model of the striatum and mesolimbic dopamine that harnesses the opponency
  between D1 and D2 MSNs to reap the computational benefits of distributional RL.  '
id: DANDI:001253/draft
identifier: DANDI:001253
license:
- spdx:CC-BY-4.0
manifestLocation:
- https://api.dandiarchive.org/api/dandisets/001253/versions/draft/assets/
name: An opponent striatal circuit for distributional reinforcement learning
repository: https://dandiarchive.org
schemaKey: Dandiset
schemaVersion: 0.6.8
url: https://dandiarchive.org/dandiset/001253/draft
version: draft
